{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "402d54c3",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/jcdevaney/pyAMPACTtutorials/blob/main/05-pyAMPACT_symbolic_Importing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8433e991-6286-45f8-8245-9ecd35e612ca",
   "metadata": {
    "id": "8433e991-6286-45f8-8245-9ecd35e612ca"
   },
   "source": [
    "<h1>pyAMPACT Importing Symbolic Data</h1>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f5fba6a-c9d7-45e2-87f4-1ad5291aad46",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2f5fba6a-c9d7-45e2-87f4-1ad5291aad46",
    "outputId": "e42b516f-8b0e-4567-fb86-f067c9347c3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing libraries...\n"
     ]
    }
   ],
   "source": [
    "from IPython.utils import io\n",
    "print('Importing libraries...')\n",
    "with io.capture_output() as captured:\n",
    "    !pip install --upgrade pandas\n",
    "    !pip install -i https://test.pypi.org/simple/ --no-deps pyampact\n",
    "    import pyampact\n",
    "    !pip install crim_intervals\n",
    "    import crim_intervals as crim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2eVow1ydvbQI",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2eVow1ydvbQI",
    "outputId": "8206cb9b-c3c1-4f94-a8c3-da90631cae8f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tDetected and imported these spine types:\n",
      "\t\t cdata-rdiss \n",
      "\n"
     ]
    }
   ],
   "source": [
    "piece_url = 'https://github.com/pyampact/pyAMPACTtutorials/blob/main/test_files/O_Virgo_Miserere.krn'\n",
    "pyamp_piece = pyampact.Score(piece_url)\n",
    "rdiss = pyamp_piece.getSpines('cdata-rdiss')\n",
    "rdiss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cLbrt5nvwZ59",
   "metadata": {
    "id": "cLbrt5nvwZ59"
   },
   "source": [
    "This notebook demonstrates how to use pyAMPACT with Humdrum. By \"Humdrum\" we are referring to the whole Humdrum ecosystem of analysis tools including humlib and the Verovio Humdrum Viewer. On its own, pyAMPACT already supports .krn as a symbolic notation file type for both importing and exporting/converting files. So this notebook goes beyond that and explains how to integrate Humdrum analysis tools into a pyAMPACT workflow.\n",
    "\n",
    "As a practical example, we get Renaissance dissonance analysis from the humlib dissonant tool. We then use pyAMPACT see which of the dissonance types correlate with various observed audio phenomena in a recording of the same piece. Since the two main components of this workflow are distributed in the Humdrum and pyAMPACT toolkits, the only way to realize this workflow is by combining these otherwise separate tools.\n",
    "\n",
    "Now let's get the score and analysis data. The critical thing here is that **the Humdrum analysis must be in the same .krn file as the score itself**. So in addition to having as many **kern spines as there are voices in the piece, the krn file should have at least one spine of analysis data. As a reference, there are several special spine types that we have dedicated methods for reading in as pandas dataframes in pyAMPACT. This table shows which pyAMPACT Score object methods to use to get each given .krn file spine type:\n",
    "\n",
    "| Spine Type | pyAMPACT Methods |\n",
    "|----------|----------|\n",
    "| **kern | .notes(), .midiPitches() |\n",
    "| **text | .lyrics() |\n",
    "| **dyanm | .dynamics() |\n",
    "| **harm | .harm(), .harmKeys(), .romanNumeral()|\n",
    "| **function | .functions() |\n",
    "| **chord | .chords() |\n",
    "| **cdata | .cdata() |\n",
    "| Any other spine type | .getSpines('name_of_spine_type') |\n",
    "\n",
    "In this notebook we're using .getSpines() to get `**cdata-rdiss` spine data into a score-time aligned pandas dataframe. We're using .getSpines because it's the generic spine importer pyAMPACT exposes for any spine types not explicitly listed in the table above.\n",
    "\n",
    "Humdrum's Renaissance dissonance classification tool is part of humlib and is also accessible on the Verovio Humdrum Viewer. You can go to any Renaissance score, then type \"dissonant\" in the text box and hit return. Then press the `+` button to the right of the text box to compile the filter which will put the analysis labels in their own spines in the .krn file. This is what that looks like for Obrecht's [Kyrie, Missa Ave regina celorum](https://verovio.humdrum.org/?file=jrp/Obr/Obr1002a-Missa_Ave_regina_celorum-Kyrie.krn).\n",
    "\n",
    "Alternatively you can add `!!!filter: dissonant` to the top of the .krn file on the left side of the score and then press`alt + c` to compile the filter (`option + c` on a mac). Then you can copy the full text and save it as your .krn file. Still another option is to use Humdrum from the terminal to create your score with analysis.\n",
    "\n",
    "In this tutorial, we've already combined that Renaissance dissonance analysis with a Humdrum file of a Tinctoris score, available [here](https://github.com/pyampact/pyAMPACTtutorials/blob/main/test_files/O_Virgo_Miserere.krn). We've already imported that piece with pyAMPACT and examined a table of the dissonance results, so now let's use CRIM to get a different type of analysis of the same piece."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rkxIzvnYA8yn",
   "metadata": {
    "id": "rkxIzvnYA8yn"
   },
   "source": [
    "<h2>Use CRIM analysis in a pyAMPACT workflow<h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "-FdZD4XxA4Gt",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-FdZD4XxA4Gt",
    "outputId": "1f406978-b7a6-4e69-b131-be9847280e77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tDetected and imported these spine types:\n",
      "\t\t cdata-rdiss \n",
      "\n",
      "Import of  failed, please check your file, path, or url.\n"
     ]
    }
   ],
   "source": [
    "from IPython.utils import io\n",
    "print('Importing CRIM...')\n",
    "with io.capture_output() as captured:\n",
    "    !pip install crim_intervals\n",
    "    import crim_intervals as crim\n",
    "piece_url = 'https://github.com/pyampact/pyAMPACTtutorials/blob/main/test_files/O_Virgo_Miserere.krn'\n",
    "crim_piece = crim.importScore(piece_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wL63WDlWBXWe",
   "metadata": {
    "id": "wL63WDlWBXWe"
   },
   "source": [
    "We'll use CRIM's Cadential Voice Function analysis, .cvfs() and then convert this piece into an MEI file that contains these CVF annotations using pyAMPACT.\n",
    "\n",
    "CRIM's CVF dataframe can be treated as if it's a pyAMPACT dataframe without any special treatment because the dataframe's index is time-aligned and the columnar index consists of part names.\n",
    "\n",
    "In a couple of cases, CRIM dataframes differ from this structure (for example .cadences() has different columns and .presentationTypes() has a different index and columns). You can still work with this CRIM data in pyAMPACT in these cases, they just require some basic restructuring of the CRIM dataframes first.\n",
    "\n",
    "Once you run the next cell, an MEI file call \"pyAMPACT-CRIM_test.mei.xml\" will appear in the menu on the left at `/pyAMPACT-CRIM_test.mei.xml`. It will be too big to view in colab, but if you double-click it you can download it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "S0kL1_3mBTYS",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 158
    },
    "id": "S0kL1_3mBTYS",
    "outputId": "22ef87d2-8703-45c5-da65-7dd50ec54051"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'cvfs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-ced119f75326>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcvf_table\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrim_piece\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvfs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpyamp_piece\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoMEI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pyAMPACT-CRIM_test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdfs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'CVF'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcvf_table\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manalysis_tag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'harm'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'cvfs'"
     ]
    }
   ],
   "source": [
    "cvf_table = crim_piece.cvfs()\n",
    "pyamp_piece.toMEI('pyAMPACT-CRIM_test', ' ', dfs={'CVF': cvf_table}, analysis_tag='harm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mU2ikrMWB4qu",
   "metadata": {
    "id": "mU2ikrMWB4qu"
   },
   "source": [
    "pyAMPACT can also create links to short excerpts of pieces, with or without extra data. We do this in the .krn format for its character economy and extensibility, via the (Verovio Humdrum Viewer)[https://verovio.humdrum.org]. Let's look at the cadential voice functions used in the last cadence of this piece which is in the last two measures. Soon we'll have the ability to include annotations in .krn output too, and then these will optionally include the annotations. But for now, let's just look at the last two measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "m5js_o7aB9gQ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m5js_o7aB9gQ",
    "outputId": "73c4095c-e417-4b8d-99c0-d603804c4ce1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://verovio.humdrum.org/?t=ISEhQ09NOiBUaW5jdG9yaXMsIEpvaGFubmVzCiEhIU9UTDogTyB2aXJnbyBtaXNlcmVyZSBtZWkKKiprZXJuCSoqa2VybgkqKmtlcm4KKnBhcnQzCSpwYXJ0MgkqcGFydDEKKnN0YWZmMwkqc3RhZmYyCSpzdGFmZjEKKkl2b3gJKkl2b3gJKkl2b3gKKkkiUGFydC0zCSpJIlBhcnQtMgkqSSJWb2ljZQoqSSdQCSpJJ1AJKkknVgo9NDUJPTQ1CT00NQoxQUFdCTRlXQk0Y2NdCi4JNGQJNGIKLgkyYwkxYQoxRQkxQgkuCi4JLgkyZyMKPTQ2CT00Ngk9NDYKMEFBCTBBCTBhCj09CT09CT09CiotCSotCSotCiEhIVJERioqa2VybjogJT1yYXRpb25hbCByaHl0aG0KISEhUkRGKiprZXJuOiBsPWxvbmcgbm90ZSBpbiBvcmlnaW5hbCBub3RhdGlvbgohISFSREYqKmtlcm46IGk9ZWRpdG9yaWFsIGFjY2lkZW50YWwKISEhT05COiBUcmFuc2xhdGVkIGZyb20gYSBrcm4gZmlsZSBvbiAyMDI0LTAzLTEzIHZpYSBweUFNUEFDVAohISF0aXRsZTogQHtPVEx9\n"
     ]
    }
   ],
   "source": [
    "pyamp_piece.show(start=45)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
